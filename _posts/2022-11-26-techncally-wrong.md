---
layout: post
title: Technically wrong by Sara Wachter-Boettche
date: "2022-11-03"
tags: book reflection
---

I recently finished reading [Technically Wrong by Sara Wachter-Boettcher](https://wwnorton.com/books/Technically-Wrong/). This book discusses how tech products have biases and assumptions baked in even if it isn't the intention of the people who created the products.

These are ideas I've been simmering I enjoyed how this book presented several concrete examples from various Silicon Valley tech companies to support this.

## Notes

- Google Photo Tagging incorrectly tagged black people as gorillas. In the book, Wachter-Boettcher questions, why wasn’t this caught in the development phase? She then pointed to the likely lack of black employees who were involved in the development process. This goes back to the lack of diversity in tech. (Related: [Google Photos Mistakenly Labels Black People as Gorillas](https://archive.nytimes.com/bits.blogs.nytimes.com/2015/07/01/google-photos-mistakenly-labels-black-people-gorillas/))
- A resume screening AI app that finds candidates similar to top-performing employees of a company. This system may start to identify people with certain traits — more “male” name, Ivy-league background, etc. as more suitable for a role, further perpetuating homogenity. (Related: [U.S. warns of discrimination in using artificial intelligence to screen job candidates](https://www.npr.org/2022/05/12/1098601458/artificial-intelligence-job-discrimination-disabilities))
- Uber is treated as a tech company, rather than a taxi service, allowing it to get around regulations that they would otherwise need to follow. Tech companies want to be seen as special.
- “The assumption that technical skills are most difficult to learn — and that if people study something else, it’s because they couldn’t hack programming. As a result, the system prizes technical abilities — systemically devalues the people who bring the very skills to the table that could strengthen products, both ethically and commercially.”

## Thoughts

This book reminded me of a post I wrote two years ago, [What are our responsibilities as software developers beyond writing code?](https://katehiga.com/2020/10/03/what-are-our-responsibilties-as-engineers.html). In it, I talk about the absence of discussions around tech ethics even in my computer science education. We don't talk enough about the ethical responsibility in tech -- and I wonder if there's even space for it.

"Move fast and break things", "Innovation"

I also see a huge overlap with the concepts discussed here, and accessibility.
